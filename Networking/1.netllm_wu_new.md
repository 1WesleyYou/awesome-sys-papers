# Review Summary: NetLLM: Adapting Large Language Models for Networking

Yuchen You (yuchenxr)

## Problem and Motivation

- **Problem addressed**: The shorback of rule based approaches as well as the DL
  based approaches in networking, whose ability of solving networking problems
are limited to seen data but behaves poorly on unseen data.
- **Why important**: Current design philosophy requires a lot of engineering overhead with poor generalization on unseen data; networking tasks need robust, generalizable models.
- **Goal**: Use LLMs for better networking adaptation, aiming for stronger generalization and reduced human engineering cost.
- **Key idea**: Adapt LLMs to networking tasks, which could enable one model for all networking related tasks.
- **Insight behind these ideas**: LLMs can generate plans for solving many kinds of problems which could generalize to unseen environments.

## Hypothesis

- Domain-adapted LLMs will improve networking performance and generalization in solving related problems.

## Solution Overview

- **Approach (Element)**:
  - Multimodal encoder for networking data, that could take in various types of data like video/audio, so we could find the best way of demonstrating networking problems.
  - Networking head for efficient output, so that the generated answers are limited to the desired output space.
  - DD-LRNA (Data-Driven Low Rank Networking Adaptation) to fine-tune LLMs efficiently.
- **Experiments**:
  - Model: mainly Llama2-7B adapted with NetLLM.
  - Tasks: VP, ABR, CJS.
  - Baselines: TRACK for VP, GENET for ABR, and Decima for CJS.
  - Metrics: MAE (VP), QoE (ABR), JCT (CJS).
  - Hardware: Linux, Intel Xeon CPUs, NVIDIA A100 GPUs.
- **Results**: NetLLM consistently outperforms baselines in the tested networking tasks like VP, ABR, and CJS, demonstrating better performance and generalization on unseen data.

## Limitations and Possible Improvements

- **Limitations**:
  - Multimodal input limited mainly to video/audio.
  - Real-time latency and compute cost not addressed.
- **Missing aspects**: No robustness/adversarial evaluation, no inference latency or resource cost analysis, and limited real-world deployment validation.
- **Possible improvements**:
  - Conduct robustness and adversarial testing to ensure a practical safe (secure) model.
  - Evaluate real-time performance and resource efficiency.

## Conclusion (Not from the template)

- **Conclusion**: NetLLM demonstrates that LLMs can serve as foundation models for networking, reducing handcrafted (human-involved) costs and improving generalization.
- **Takeaways**: LLMs are promising tools for networking and OS-related tasks.
