# Summary of "Exploring ChatGPT's Capabilities on Vulnerability Management"

Yuchen You (yuchenxr)

## Problem and Motivation

- The LLM models, including the ChatGPT, has shown its great potential in various software engineering tasks, but it is unclear whether that GPT can complete more complicated real-world vulnerability tasks in many kinds of fields.
- The prompt engineering could help with the performance of LLMs, but it's not always that more complex prompts lead to better results.
- How to make use of the prompts to achieve the best performance in different vulnerability management tasks is still an open question.
- Through investigation of the ChatGPT's capabilities on six vulnerability management tasks, the authors aim to imply some fields that are potential future research directions.

## Hypothesis

- The LLM (ChatGPT) can help a lot with the vulnerability management tasks, including the bug reports summarization, security bug report identification, vulnerability severity evaluation, vulnerability repair, patch correctness assessment, and stable patch classification.

## Solution Overview

### Tests Conducted in ChatGPT's Ability on Vulnerability Management

- Bug Report Summarization
  - Baseline (Test): iTAPE
  - Best ChatGPT Setting: gpt-4 few-shot (providing a few examples in the prompt)
  - Result: Outperforms iTAPE across ROUGE metrics  
  - Implication:
    - ChatGPT is naturally strong in text summarization; simple few-shot prompts work better than complex ones
    - introducing additional information and expertise in the prompt can lead to confusion for ChatGPT in understanding this task
- Security Bug Report Identification
  - Baseline (Test): Farsec, CASMS, DKG
  - Best ChatGPT Setting: gpt-4 expertise prompt (telling ChatGPT that he is an expert in security bug identification, and are provided with general-info of the related domain knowledge).
  - Result: Better than Farsec and CASMS, but worse than DKG; high recall but low precision  
  - Implication:
    - summary of domain knowledge can directly benefit the improvement of ChatGPT's performance in security bug report identification
    - when providing demonstration examples, how to make ChatGPT focus on helpful information rather than irrelevant content is an interesting question.
    - infos that are not detailed enough can mislead ChatGPT, details about the impact and exploitability of bugs are particularly helpful.
- Vulnerability Severity Evaluation
  - Baseline (Test): DiffCVSS
  - Best ChatGPT Setting: gpt-3.5/4 self-heuristic prompt (providing the LLM with the GPT generated summary of CVSS scoring rules)
  - Result: Slightly worse (inferior to) overall than DiffCVSS, but surpasses SOTA on AV:Network recall  
  - Implication:
    - providing the description of CVSS metrics in the expertise template slightly improves the performance
    - can reduce the length of the demonstration examples by half on average
    - extracting expertise by leveraging ChatGPT and incorporating the extracted expertise into prompt is an interesting future research direction
- Vulnerability Repair
  - Baseline (Test): ExtractFix, LLMset
  - Best ChatGPT Setting: gpt-4 expertise prompt
  - Result: better than LLMset on most cases but very low correctness on some cases like the CVE-2017-7601
  - Implication:  
    - directly finishing the task with ChatGPT's response can be impractical.
    - ChatGPT can be a great choice when traditional program analysis methods fail
- Patch Correctness Assessment
  - Baseline (Test): Quatrain, Invalidator, Panther
  - Best ChatGPT Setting: gpt-4 code-only prompt
  - Result: Outperforms all baselines, especially in F1 and negative recall (detecting incorrect patches)  
  - Implication: Too much information (description + code) can mislead ChatGPT; carefully reducing input information improves performance  
- Stable Patch Classification
  - Baseline (Test): PatchNet
  - Best ChatGPT Setting: gpt-3.5 general-info prompt
  - Result: Higher recall than PatchNet (0.996 vs 0.907), but lower precision and accuracy overall
  - Implication: ChatGPT tends to over-classify patches as "stable";
    - ChatGPT's misunderstanding of what constitutes a stable patch, resulting in a hallucination
- User Study (by Bug Report Summarization)
  - Baseline (Test): iTAPE
  - Best ChatGPT Setting: multiple prompts (0-shot, few-shot, expertise, etc.)  
  - Result: generally produces better summarizations in terms of correctness compared to iTAPE; iTAPE rated higher in conciseness

## Limitations and Possible Improvements

- Evaluation setting: The study are tested in static datasets but not in real-world (especially industry) scenarios, which is not practical.
  - Potential improvement: Conduct real-world case studies to validate findings.
- Experiment rang: The study only focuses on 6 vulnerability management tasks, and there fields are more about analysis but not testing on vulnerability operations or even detection/defence.
  - Potential improvement: use the agent to test on more vulnerability management tasks dynamically.
